settings:
  docker:
    requirements: requirements.txt
    python_package_installer: uv
    apt_packages: 
      - git
    environment:
      PJRT_DEVICE: CUDA
      USE_TORCH_XLA: "false"
      MKL_SERVICE_FORCE_INTEL: "1"
      PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
  orchestrator.lightning:
      machine_type: CPU
      user_id: USERID
      api_key: APIKEY
      username: USERNAME
      teamspace: TEAMSPACE

model:
  name: llm-finetuning-gpt2-large
  description: "Fine-tune GPT-2 on larger GPU."
  tags:
    - llm
    - finetuning
    - gpt2-large

parameters:
  base_model_id: gpt2-large

steps:
  prepare_data:
    parameters:
      dataset_name: squad
      dataset_size: 1000
      max_length: 256

  finetune:
    parameters:
      num_train_epochs: 3
      per_device_train_batch_size: 4

    settings:
        orchestrator.lightning:
          machine_type: A10G