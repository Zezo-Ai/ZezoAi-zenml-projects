# Creditâ€‘Scoring EU AI Act Demo

> A ZenMLâ€‘powered endâ€‘toâ€‘end creditâ€‘scoring workflow that automatically generates the technical evidence required by the EU AI Act.

## ðŸš€ Project Overview

The project implements three main pipelines:

1. **Feature Engineering Pipeline**: Handles data governance and preprocessing (Articles 10, 12, 15)
   â€“ `ingest â†’ data_splitter â†’ data_preprocessor â†’ generate_compliance_metadata`

2. **Training Pipeline**: Implements model training, evaluation, and risk assessment (Articles 9, 11, 15)  
   â€“ `train_model â†’ evaluate_model â†’ risk_assessment`

3. **Deployment Pipeline**: Manages human oversight, deployment, and monitoring (Articles 14, 17, 18)
   â€“ `approve_deployment â†’ modal_deployment â†’ generate_sbom â†’ post_market_monitoring â†’ generate_annex_iv_documentation`

Each run automatically versions its inputs, logs hashes & metrics, and generates a complete Annex IV draft with all required compliance artifacts. These artifacts include an SBOM (Software Bill of Materials), monitoring plan, data profiling reports, risk assessments, and technical documentation.

## Architecture

![End-to-End Architecture](assets/e2e.png)

For detailed diagrams of each pipeline and their compliance mapping, see [Pipeline Diagrams](assets/diagrams.md).

## Project Structure

```bash
credit_scoring_ai_act/
â”œâ”€â”€ app/ # Modal deployment app
â”‚   â”œâ”€â”€ modal_deployment.py # Modal deployment script
â”‚   â””â”€â”€ schemas.py # Pydantic models for API
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # Feature engineering pipeline
â”‚   â”‚   â”œâ”€â”€ training.py # Model training pipeline
â”‚   â”‚   â””â”€â”€ deployment.py # Deployment pipeline
â”‚   â”œâ”€â”€ steps/
â”‚   â”‚   â”œâ”€â”€ feature_engineering/ # Feature engineering steps
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest.py # Load CSV â†’ log SHAâ€‘256, WhyLogs profile
â”‚   â”‚   â”‚   â”œâ”€â”€ data_preprocessor.py # Basic feature engineering
â”‚   â”‚   â”‚   â”œâ”€â”€ data_splitter.py # Split dataset into train/test
â”‚   â”‚   â”‚   â””â”€â”€ generate_compliance_metadata.py # Generate compliance metadata
â”‚   â”‚   â”œâ”€â”€ training/ # Training steps
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py # XGBoost / sklearn model
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py # Standard + Fairness metrics
â”‚   â”‚   â”‚   â””â”€â”€ risk_assessment.py # Risk assessment
â”‚   â”‚   â””â”€â”€ deployment/ # Deployment steps
â”‚   â”‚       â”œâ”€â”€ approve.py # Humanâ€‘inâ€‘loop gate (approve_deployment step)
â”‚   â”‚       â”œâ”€â”€ deploy.py # Deployment to Modal
â”‚   â”‚       â”œâ”€â”€ post_market_monitoring.py # Postâ€‘market monitoring
â”‚   â”‚       â”œâ”€â”€ generate_sbom.py # Generate Software Bill of Materials
â”‚   â”‚       â””â”€â”€ post_run_annex.py # Generate Annex IV documentation
â”‚   â”œâ”€â”€ utils/ # Shared utilities
â”‚   â”‚   â”œâ”€â”€ modal_utils.py # Modal Volume operations
â”‚   â”‚   â”œâ”€â”€ preprocess.py # Custom sklearn transformers
â”‚   â”‚   â”œâ”€â”€ eval.py # Evaluation utils
â”‚   â”‚   â”œâ”€â”€ incidents.py # Incident reporting system
â”‚   â”‚   â”œâ”€â”€ risk_dashboard.py # Risk visualization dashboard
â”‚   â”‚   â”œâ”€â”€ visualizations.py # Visualization utils
â”‚   â”‚   â””â”€â”€ model_definition.py # ZenML model definition
â”‚   â”‚
â”‚   â”œâ”€â”€ configs/ # Configuration files
â”‚   â””â”€â”€ constants.py # Centralized configuration constants
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ risk/ # Risk assessment documentation
â”‚   â”‚   â”œâ”€â”€ incident_log.json # Incident tracking
â”‚   â”‚   â””â”€â”€ risk_register.xlsx # Risk register
â”‚   â”œâ”€â”€ releases/ # Compliance artifacts organized by run ID
â”‚   â”‚   â””â”€â”€ <run_id>/
â”‚   â”‚      â”œâ”€â”€ annex_iv_cs_deployment.md  # Annex IV technical documentation
â”‚   â”‚      â”œâ”€â”€ evaluation_results.yaml    # Model performance metrics and evaluations
â”‚   â”‚      â”œâ”€â”€ git_info.md                # Git commit and repository information
â”‚   â”‚      â”œâ”€â”€ monitoring_plan.json       # Model monitoring configuration
â”‚   â”‚      â”œâ”€â”€ README.md                  # Release-specific information
â”‚   â”‚      â”œâ”€â”€ risk_scores.yaml           # Risk assessment scores and analysis
â”‚   â”‚      â”œâ”€â”€ sbom.json                  # Software Bill of Materials
â”‚   â”‚      â””â”€â”€ whylogs_profile.html       # Data profiling report
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ annex_iv_template.j2 # Annex IV template
â”‚       â”œâ”€â”€ sample_inputs.json # Sample inputs for Annex IV
â”‚       â””â”€â”€ qms/ # Quality management system documentation
â”‚           â”œâ”€â”€ qms_template.md # Core QMS document
â”‚           â”œâ”€â”€ roles_and_responsibilities.md # Role assignments
â”‚           â”œâ”€â”€ audit_plan.md # Audit schedule and methodology
â”‚           â””â”€â”€ sops/ # Standard Operating Procedures
â”‚               â”œâ”€â”€ model_release_sop.md # Model release protocol
â”‚               â”œâ”€â”€ drift_monitoring_sop.md # Monitoring procedures
â”‚               â”œâ”€â”€ incident_response_sop.md # Incident handling
â”‚               â”œâ”€â”€ risk_mitigation_sop.md # Risk management process
â”‚               â””â”€â”€ data_ingestion_sop.md # Data handling procedures
â”‚
â”œâ”€â”€ assets/ # Pipeline diagrams and documentation
â”‚   â”œâ”€â”€ deployment-pipeline.png # Deployment pipeline diagram
â”‚   â”œâ”€â”€ diagrams.md # Detailed pipeline diagrams with explanations
â”‚   â”œâ”€â”€ e2e.png # End-to-end architecture diagram
â”‚   â”œâ”€â”€ feature-engineering-pipeline.png # Feature engineering pipeline diagram
â”‚   â”œâ”€â”€ modal-deployment.png # Modal deployment diagram
â”‚   â””â”€â”€ training-pipeline.png # Training pipeline diagram
â”œâ”€â”€ data/ # Dataset directory
â”‚   â””â”€â”€ credit_scoring.csv # Credit scoring dataset
â”œâ”€â”€ visualizations/ # WhyLogs and other visualization outputs
â”œâ”€â”€ run.py # CLI entrypoint
â”œâ”€â”€ COMPLIANCE.md # EU AI Act compliance mapping
â””â”€â”€ README.md
```

## Running Pipelines

```bash
# Run feature engineering pipeline (Articles 10, 12)
python run.py --feature

# Run model training pipeline (Articles 9, 11, 15)
python run.py --train

# Run deployment pipeline (Articles 14, 17, 18)
python run.py --deploy
```

Options:

- `--auto-approve` for nonâ€‘interactive deployment
- `--no-cache` to disable ZenML caching
- `--config-dir <path>` to override default configs

### Configuration

Pipeline configurations are stored in the `src/configs/` directory:

- `feature_engineering.yaml`
- `training.yaml`
- `deployment.yaml`

You can specify a custom config directory using the `--config-dir` option.

## Modal Deployment

![Modal Deployment](assets/modal-deployment.png)

The project implements a serverless deployment using Modal with comprehensive monitoring and incident reporting capabilities:

- FastAPI application with documented endpoints
- Automated model and preprocessing pipeline loading
- Drift detection and incident reporting
- Standardized storage paths for compliance artifacts
- Complete incident reporting system for Article 18 compliance

## ðŸ”— EU AI Act Compliance Mapping

For a complete overview of the EU AI Act compliance mapping, refer to the [COMPLIANCE.md](COMPLIANCE.md) file.

## Compliance Directory Structure

The repository uses a structured approach to organizing compliance artifacts:

| Directory               | Purpose                                  | Auto/Manual |
| ----------------------- | ---------------------------------------- | ----------- |
| **releases/**           | Compliance artifacts organized by run ID | Auto        |
| **risk/**               | Risk assessment and incident tracking    | Auto/Manual |
| **templates/**          | Templates for document generation        | Manual      |
| **templates/qms/**      | Quality Management System documentation  | Manual      |
| **templates/qms/sops/** | Standard Operating Procedures            | Manual      |

The **releases/** directory contains automatically generated artifacts for each pipeline run, including:

- Annex IV technical documentation (annex_iv_cs_deployment.md)
- Software Bill of Materials (sbom.json)
- Model performance metrics (evaluation_results.yaml)
- Risk assessment scores (risk_scores.yaml)
- Data profiling report (whylogs_profile.html)
- Monitoring configuration (monitoring_plan.json)
- Git repository information (git_info.md)

## ðŸ“‹ Quality Management System (Article 17)

This repo delivers all _technical evidence_ (lineage, metadata, logs) required by the EU AI Act. For a complete QMS, you must also maintain formal QMS documentation.

See `docs/templates/qms/` for starter templates:

- **Quality Policy** (`qms_template.md`)
- **Roles & Responsibilities** (`roles_and_responsibilities.md`)
- **Audit Plan** (`audit_plan.md`)
- **SOPs** (`sops/` folder: data ingestion, model release, risk mitigation, etc.)
