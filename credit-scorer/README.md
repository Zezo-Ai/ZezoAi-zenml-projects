# Creditâ€‘Scoring EU AI Act Demo

> A ZenMLâ€‘powered endâ€‘toâ€‘end creditâ€‘scoring workflow that automatically generates the technical evidence required by the [EU AI Act](https://www.zenml.io/blog/understanding-the-ai-act-february-2025-updates-and-implications). This project demonstrates how to build AI systems that meet regulatory requirements while maintaining development efficiency. The EU AI Act, which came into effect in 2024, introduces mandatory compliance requirements for high-risk AI systems, making automated compliance crucial for organizations deploying AI in regulated environments.

![Streamlit Compliance Dashboard](assets/streamlit-app.png)

## ðŸš€ Project Overview

The project implements three main pipelines:

1. [**Feature Engineering Pipeline**](src/pipelines/feature_engineering.py): Handles data governance and preprocessing (Articles 10, 12, 15)
   â€“ `ingest â†’ data_splitter â†’ data_preprocessor`

2. [**Training Pipeline**](src/pipelines/training.py): Implements model training, evaluation, and risk assessment (Articles 9, 11, 15)
   â€“ `train_model â†’ evaluate_model â†’ risk_assessment`

3. [**Deployment Pipeline**](src/pipelines/deployment.py): Manages human oversight, deployment, and monitoring (Articles 14, 17, 18)
   â€“ `approve_deployment â†’ modal_deployment â†’ generate_sbom â†’ post_market_monitoring â†’ generate_annex_iv_documentation`

Each run automatically versions its inputs, logs hashes & metrics, and generates a complete Annex IV draft with all required compliance artifacts. These artifacts include an SBOM (Software Bill of Materials), monitoring plan, data profiling reports, risk assessments, and technical documentation.

## Architecture

![End-to-End Architecture](assets/e2e.png)

For detailed diagrams of each pipeline and their compliance mapping, see [Pipeline Diagrams](assets/diagrams.md).

## Project Structure

```bash
credit_scoring_ai_act/
â”œâ”€â”€ modal_app/ # Modal deployment app
â”‚   â”œâ”€â”€ modal_deployment.py # Modal deployment script
â”‚   â””â”€â”€ schemas.py # Pydantic models for API
â”œâ”€â”€ scripts/ # Scripts for updating compliance data
â”‚   â”œâ”€â”€ update_risk_register.py # Update the risk register
â”‚   â””â”€â”€ test_compliance_tracker.py # Test the compliance tracker
â”œâ”€â”€ streamlit_app/ # Streamlit app for compliance tracking
â”‚   â”œâ”€â”€ components/ # Streamlit components
â”‚   â”‚   â”œâ”€â”€ executive_summary.py # Executive summary component
â”‚   â”‚   â”œâ”€â”€ risk_dashboard.py # Risk dashboard component
â”‚   â”‚   â””â”€â”€ data_processor.py # Data processing and calculation utilities
â”‚   â”œâ”€â”€ config.py # Configuration settings
â”‚   â””â”€â”€ main.py # Streamlit app entrypoint
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # Feature engineering pipeline
â”‚   â”‚   â”œâ”€â”€ training.py # Model training pipeline
â”‚   â”‚   â””â”€â”€ deployment.py # Deployment pipeline
â”‚   â”œâ”€â”€ steps/
â”‚   â”‚   â”œâ”€â”€ feature_engineering/ # Feature engineering steps
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest.py # Load CSV â†’ log SHAâ€‘256, WhyLogs profile
â”‚   â”‚   â”‚   â”œâ”€â”€ data_preprocessor.py # Basic feature engineering
â”‚   â”‚   â”‚   â””â”€â”€  data_splitter.py # Split dataset into train/test
â”‚   â”‚   â”œâ”€â”€ training/ # Training steps
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py # XGBoost / sklearn model
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py # Standard + Fairness metrics
â”‚   â”‚   â”‚   â””â”€â”€ risk_assessment.py # Risk assessment
â”‚   â”‚   â””â”€â”€ deployment/ # Deployment steps
â”‚   â”‚       â”œâ”€â”€ approve.py # Humanâ€‘inâ€‘loop gate (approve_deployment step)
â”‚   â”‚       â”œâ”€â”€ deploy.py # Deployment to Modal
â”‚   â”‚       â”œâ”€â”€ post_market_monitoring.py # Postâ€‘market monitoring
â”‚   â”‚       â”œâ”€â”€ generate_sbom.py # Generate Software Bill of Materials
â”‚   â”‚       â””â”€â”€ post_run_annex.py # Generate Annex IV documentation
â”‚   â”œâ”€â”€ utils/ # Shared utilities
â”‚   â”‚   â”œâ”€â”€ modal_utils.py # Modal Volume operations
â”‚   â”‚   â”œâ”€â”€ preprocess.py # Custom sklearn transformers
â”‚   â”‚   â”œâ”€â”€ eval.py # Evaluation utils
â”‚   â”‚   â”œâ”€â”€ incidents.py # Incident reporting system
â”‚   â”‚   â”œâ”€â”€ risk_dashboard.py # Risk visualization dashboard
â”‚   â”‚   â”œâ”€â”€ annex_iv.py # Annex IV template generation
â”‚   â”‚   â”œâ”€â”€ compliance/ # Compliance tracking system
â”‚   â”‚   â”œâ”€â”€ template.py # Template generation utils
â”‚   â”‚   â””â”€â”€ visualizations.py # Visualization utils
â”‚   â”‚
â”‚   â”œâ”€â”€ configs/ # Configuration files
â”‚   â””â”€â”€ constants.py # Centralized configuration constants
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ compliance.md # EU AI Act Article to Pipeline Step mapping
â”‚   â”œâ”€â”€ risk/ # Risk assessment documentation
â”‚   â”‚   â”œâ”€â”€ incident_log.json # Incident tracking
â”‚   â”‚   â””â”€â”€ risk_register.xlsx # Risk register
â”‚   â”œâ”€â”€ releases/ # Compliance artifacts organized by run ID
â”‚   â”‚   â””â”€â”€ <run_id>/
â”‚   â”‚      â”œâ”€â”€ annex_iv_cs_deployment.md  # Annex IV technical documentation
â”‚   â”‚      â”œâ”€â”€ evaluation_results.yaml    # Model performance metrics and evaluations
â”‚   â”‚      â”œâ”€â”€ git_info.md                # Git commit and repository information
â”‚   â”‚      â”œâ”€â”€ monitoring_plan.json       # Model monitoring configuration
â”‚   â”‚      â”œâ”€â”€ README.md                  # Release-specific information
â”‚   â”‚      â”œâ”€â”€ risk_scores.yaml           # Risk assessment scores and analysis
â”‚   â”‚      â”œâ”€â”€ sbom.json                  # Software Bill of Materials
â”‚   â”‚      â””â”€â”€ whylogs_profile.html       # Data profiling report
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ annex_iv_template.j2 # Annex IV template (Jinja2)
â”‚       â”œâ”€â”€ sample_inputs.json # Sample inputs for Annex IV template
â”‚       â””â”€â”€ qms/ # Quality management system documentation
â”‚           â”œâ”€â”€ qms_template.md # Core QMS document
â”‚           â”œâ”€â”€ roles_and_responsibilities.md # Role assignments
â”‚           â”œâ”€â”€ audit_plan.md # Audit schedule and methodology
â”‚           â””â”€â”€ sops/ # Standard Operating Procedures
â”‚               â”œâ”€â”€ model_release_sop.md # Model release protocol
â”‚               â”œâ”€â”€ drift_monitoring_sop.md # Monitoring procedures
â”‚               â”œâ”€â”€ incident_response_sop.md # Incident handling
â”‚               â”œâ”€â”€ risk_mitigation_sop.md # Risk management process
â”‚               â””â”€â”€ data_ingestion_sop.md # Data handling procedures
â”‚
â”œâ”€â”€ assets/ # Pipeline diagrams and documentation
â”‚   â”œâ”€â”€ deployment-pipeline.png # Deployment pipeline diagram
â”‚   â”œâ”€â”€ diagrams.md # Detailed pipeline diagrams with explanations
â”‚   â”œâ”€â”€ e2e.png # End-to-end architecture diagram
â”‚   â”œâ”€â”€ feature-engineering-pipeline.png # Feature engineering pipeline diagram
â”‚   â”œâ”€â”€ modal-deployment.png # Modal deployment diagram
â”‚   â””â”€â”€ training-pipeline.png # Training pipeline diagram
â”œâ”€â”€ data/ # Dataset directory
â”‚   â””â”€â”€ credit_scoring.csv # Credit scoring dataset
â”œâ”€â”€ run.py # CLI entrypoint
â””â”€â”€ README.md
```

## Running Pipelines

```bash
# Run feature engineering pipeline (Articles 10, 12)
python run.py --feature

# Run model training pipeline (Articles 9, 11, 15)
python run.py --train

# Run deployment pipeline (Articles 14, 17, 18)
python run.py --deploy
```

Options:

- `--auto-approve` for nonâ€‘interactive deployment
- `--no-cache` to disable ZenML caching
- `--config-dir <path>` to override default configs

### Configuration

Pipeline configurations are stored in the `src/configs/` directory:

- [`feature_engineering.yaml`](src/configs/feature_engineering.yaml)
- [`training.yaml`](src/configs/training.yaml)
- [`deployment.yaml`](src/configs/deployment.yaml)

You can specify a custom config directory using the `--config-dir` option.

## Compliance Dashboard

The project includes a Streamlit-based compliance dashboard that provides:

- Real-time visibility into EU AI Act compliance status
- Executive summary of current risk levels and compliance metrics
- Detailed risk assessment visualizations and tracking
- Access to all compliance artifacts from a single interface
- Generated Annex IV documentation with export options

To run the dashboard:

```bash
# Launch the Streamlit compliance dashboard
python run_dashboard.py
```

## Modal Deployment

![Modal Deployment](assets/modal-deployment.png)

The project implements a serverless deployment using Modal with basic monitoring and incident reporting capabilities:

- FastAPI application with documented endpoints
- Automated model and preprocessing pipeline loading
- Basic incident reporting functionality
- Standardized storage paths for compliance artifacts

## ðŸ”— EU AI Act Compliance Mapping

For an overview of how the creditâ€‘scoring pipeline maps to the articles of the EU AI Act, refer to the [compliance_matrix.md](docs/compliance_matrix.md) file.

## Compliance Directory Structure

The repository uses a structured approach to organizing compliance artifacts:

| Directory               | Purpose                                  | Auto/Manual |
| ----------------------- | ---------------------------------------- | ----------- |
| **releases/**           | Compliance artifacts organized by run ID | Auto        |
| **risk/**               | Risk assessment and incident tracking    | Auto/Manual |
| **templates/**          | Templates for document generation        | Manual      |
| **templates/qms/**      | Quality Management System documentation  | Manual      |
| **templates/qms/sops/** | Standard Operating Procedures            | Manual      |

The **releases/** directory contains automatically generated artifacts for each pipeline run, including:

- [Annex IV technical documentation](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/annex_iv_cs_deployment.md)
- [Software Bill of Materials](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/sbom.json)
- [Model performance metrics](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/evaluation_results.yaml)
- [Risk assessment scores](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/risk_scores.yaml)
- [Data profiling report](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/whylogs_profile.html)
- [Monitoring configuration](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/monitoring_plan.json)
- [Git repository information](docs/releases/e7243682-a6f7-4f1d-b8ff-dc8da754994a/git_info.md)

## ðŸ“„ Annex IV Documentation

The repository includes an automated Annex IV technical documentation generator that creates comprehensive EU AI Act-compliant documentation for each pipeline run.

### Documentation Components

1. **Template System**:

   - `annex_iv_template.j2` - Jinja2 template for Annex IV documents
   - `sample_inputs.json` - Default inputs for Annex IV fields
   - `src/utils/template.py` - Template rendering utilities
   - `src/utils/annex_iv.py` - Helper functions for metadata collection

2. **Generation Process**:

   - Automatically collects metadata from pipeline runs
   - Extracts metrics from evaluation results
   - Uses sample inputs for standardized sections
   - Assembles a complete technical documentation file

3. **Usage**:
   ```python
   # To customize the template inputs:
   1. Edit docs/templates/sample_inputs.json with your specific values
   2. The template utility will load these values automatically
   ```

## ðŸ“‹ Quality Management System (Article 17)

This repo delivers all _technical evidence_ (lineage, metadata, logs) required by the EU AI Act. For a complete QMS, you must also maintain formal QMS documentation.

See `docs/templates/qms/` for starter templates:

- **Quality Policy** (`qms_template.md`)
- **Roles & Responsibilities** (`roles_and_responsibilities.md`)
- **Audit Plan** (`audit_plan.md`)
- **SOPs** (`sops/` folder: data ingestion, model release, risk mitigation, etc.)
