{
  "provider": "ZenML GmbH",
  "description": "EU AI Act Compliant Credit Scoring System for financial institutions",
  "intended_purpose": "To evaluate credit risk for loan applicants by providing an objective, fair, and transparent score based on financial history and demographic data.",
  "additional_interactions": "The system processes applicant data through a standardized input format and provides credit risk scores through a REST API. It integrates with ZenML for model versioning and deployment management, and Modal for serverless deployment. The system maintains a risk register and incident log for compliance tracking.",
  "design_assumptions": "The model assumes applicants have a reasonably complete financial history and operates under stable macroeconomic conditions. It also assumes data quality standards are maintained across input sources.",
  "compliance_tradeoffs": "To ensure EU AI Act compliance, we prioritized model explainability and fairness over maximum predictive performance. We implemented post-processing fairness constraints and transparent feature importance, which slightly reduced raw accuracy but significantly improved demographic fairness and transparency.",
  "hardware_requirements": "Standard deployment: 2 vCPU, 1 GB RAM, 10GB disk",
  "computational_resources": "Training infrastructure: 2 vCPU, 1 GB RAM. Inference runs on standard 2 vCPU, 1 GB RAM instances with auto-scaling based on demand. ZenML orchestration requires minimal additional resources.",
  "data_methodology": "Training data is derived from a balanced historical loan dataset spanning 5 years with approximately 20,000 records. Sensitive attributes (gender, age) are protected during model training with fairness constraints. Feature engineering follows established credit risk assessment standards, with data cleaning and normalization protocols to handle outliers and missing values.",
  "bias_mitigation": "Our comprehensive bias mitigation approach includes: (1) Balanced dataset sampling for training, (2) Regular bias audits across protected attributes including gender, age, education level, family status, and housing type, (3) Post-processing fairness adjustments to equalize performance across demographic groups, and (4) Continuous monitoring of selection rate disparities for real-time fairness assessment.",
  "oversight_assessment": "Human oversight is implemented through a mandatory approval workflow before any deployment. The system's risk score output includes confidence intervals and feature importance to assist human reviewers. High-risk cases and those with potential bias are automatically flagged for human review, with specific thresholds established for different demographic groups.",
  "continuous_compliance_plan": "The continuous compliance framework includes: (1) Daily automated monitoring of model drift metrics, (2) Weekly fairness audits across protected attributes, (3) Monthly performance reviews of model outputs, (4) Quarterly comprehensive compliance reassessments with stakeholder reviews, and (5) Incident response protocols for any detected bias or performance issues.",
  "cybersec_measures": "Security measures include: (1) End-to-end encryption for all data in transit and at rest, (2) Access controls with role-based permissions for model interaction, (3) Audit logging of all system access and predictions, (4) Regular vulnerability assessments of the deployment infrastructure, (5) Secure CI/CD pipeline with automated security scanning, and (6) Protection against model extraction or adversarial attacks.",
  "limitations": "The system has verified limitations including: (1) Lower accuracy for applicants with limited credit history, (2) Potential for reduced performance during significant macroeconomic shifts, (3) Reduced explainability for edge cases, and (4) Applicability only within the regulatory jurisdiction it was trained for. The model should always be used as a decision support tool, not as the sole determining factor for credit decisions.",
  "unintended_outcomes": "Potential unintended outcomes include: (1) Risk of perpetuating historical biases present in training data despite mitigation measures, (2) Possible feedback loops where denied applicants cannot build sufficient credit history for future approval, (3) Over-reliance on algorithmic decisions by human reviewers (automation bias), and (4) Potential for emerging disparities across intersectional demographic groups not specifically monitored.",
  "input_specifications": "Required input data includes: (1) Financial history (income, debt-to-income ratio, existing credit), (2) Employment data (job stability, industry sector), (3) Credit bureau information (credit score, previous defaults), (4) Payment history (timeliness, reliability), and (5) Demographic information (used only for fairness assessment). All numerical inputs must be normalized according to the documented preprocessing pipeline.",
  "metric_appropriateness": "The selected metrics provide a balanced assessment of model performance and fairness: (1) Accuracy (91.9%) measures overall predictive capability, (2) AUC (0.75) assesses discrimination ability across thresholds, (3) Selection rate disparities across protected groups quantify fairness, and (4) Per-group accuracy measures ensure consistent performance. These metrics align with both regulatory requirements and business objectives of fair lending.",
  "standards_list": "The system adheres to: (1) ISO/IEC 27001:2022 for information security management, (2) IEEE 7010-2020 for wellbeing impact assessment, (3) ISO/IEC 25024:2015 for data quality, (4) CEN Workshop Agreement 17145-1 for validation methodologies in AI, and (5) ISO/IEC 29119 for software testing.",
  "post_market_plan": "The comprehensive post-market monitoring includes: (1) Daily automated performance monitoring with statistical drift detection, (2) Weekly fairness audits across protected attributes, (3) Structured feedback collection through API endpoints for user experience, (4) Quarterly compliance reassessment with stakeholder review, and (5) Incident tracking and response protocols for any detected issues or complaints.",
  "deployment_type": "Modal + FastAPI (Serverless API deployment with auto-scaling)",
  "product_image_url": "../../../assets/e2e.png",
  "ui_screenshot_url": "../../../assets/streamlit-app.png",
  "user_doc_link": "../../../README.md",
  "api_doc_link": "../../../modal_app/api_guide.md",
  "arch_diagram_url": "../../../assets/modal-deployment.png",
  "declaration_of_conformity": "EU Declaration of Conformity for Credit Scoring AI System\n\nProvider: ZenML GmbH\nAddress: Example Street 123, 80331 Munich, Germany\nContact: compliance@zenml.io\n\nWe, ZenML GmbH, declare under our sole responsibility that the Credit Scoring AI System, version 1.3.0, complies with the relevant requirements set out in Section 2 of the EU AI Act (Regulation 2024/1689).\n\nThe system has undergone conformity assessment in accordance with Article 43 and meets all requirements related to:\n- Risk management (Article 9)\n- Data governance (Article 10)\n- Technical documentation (Article 11)\n- Record keeping (Article 12)\n- Transparency (Article 13)\n- Human oversight (Article 14)\n- Accuracy, robustness and cybersecurity (Article 15)\n- Post-market monitoring (Articles 16-17)\n- Incident reporting (Articles 18-19)\n\nThis declaration is kept at the disposal of national competent authorities for 10 years after the system has been placed on the market or put into service, in compliance with Article 47.\n\nSigned for and on behalf of ZenML GmbH\n\nMunich, May 18, 2025\n\nLouisa Gerryts\nChief Compliance Officer",
  "model_architecture": "Gradient Boosting Decision Tree (XGBoost)",
  "optimization_objective": "Maximize balanced accuracy while minimizing fairness disparities across protected demographic groups",
  "performance_metrics": {
    "accuracy": null,
    "auc": null
  },
  "fairness_assessment": {
    "demographic_parity_gender": null,
    "equal_opportunity_gender": null,
    "accuracy_disparity_gender": null,
    "selection_rate_disparity_gender": null,
    "accuracy_disparity_education": null,
    "selection_rate_disparity_education": null,
    "accuracy_disparity_housing": null,
    "selection_rate_disparity_housing": null,
    "overall_fairness_score": null
  },
  "risk_management_system": "Our comprehensive risk management system implements Article 9 requirements through:\n\n1) Risk Identification: Cross-functional workshops with stakeholders identify potential risks across technical performance, fairness, data quality, and operational domains.\n\n2) Risk Assessment: Standardized scoring matrix evaluates likelihood and impact of each risk, with special attention to high-risk bias factors with an overall risk score of 0.525.\n\n3) Risk Mitigation: Each identified risk has documented controls and responsible parties, with specific focus on bias mitigation achieving a risk score reduction of approximately 20%.\n\n4) Continuous Monitoring: Automated drift detection alerts stakeholders to potential performance issues, with thresholds calibrated to regulatory requirements.\n\n5) Regular Review: Quarterly reviews evaluate risk control effectiveness, with particular attention to risk measures of accuracy (risk score 0.25) and bias (risk score 0.8).\n\nThe system prioritizes monitoring and mitigating risks related to data quality, model fairness, security vulnerabilities, and performance degradation.",
  "lifecycle_changes_log": "v1.0.0 (2025-03-01): Initial production model with baseline fairness constraints\n\nv1.1.0 (2025-03-15): Enhanced preprocessing pipeline for improved missing value handling\n\nv1.2.0 (2025-04-10): Implemented post-processing fairness adjustments based on initial performance data\n\nv1.2.1 (2025-04-25): Optimized feature engineering process for protected attributes\n\nv1.3.0 (2025-05-18): Comprehensive update with improved bias mitigation and EU AI Act compliance documentation",
  "frameworks": {
    "cyclonedx-python-lib": ">=10.0.1",
    "fairlearn": ">=0.12.0",
    "pdfkit": ">=1.0.0",
    "pyyaml": ">=6.0.0",
    "markdown": ">=3.8",
    "matplotlib": ">=3.10.3",
    "modal": ">=0.74.55",
    "openpyxl": ">=3.1.5",
    "pandas": ">=2.2.3",
    "plotly": ">=6.0.1",
    "scikit-learn": ">=1.6.1",
    "seaborn": ">=0.13.2",
    "slack-sdk": ">=3.35.0",
    "streamlit": ">=1.45.1",
    "streamlit-option-menu": ">=0.4.0",
    "tabulate": ">=0.9.0",
    "weasyprint": ">=65.1",
    "whylogs": "latest",
    "xlsxwriter": ">=3.2.3",
    "zenml": ">=0.82.1"
  }
}
