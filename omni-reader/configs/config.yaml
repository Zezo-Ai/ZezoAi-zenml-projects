# Pipeline configuration
build: "ocr-evaluation-pipeline-20254003"
run_name: "ocr_evaluation_run"

# Enable flags
enable_artifact_metadata: True
enable_artifact_visualization: True
enable_cache: False
enable_step_logs: True

# Pipeline parameters
parameters:
  mode: "evaluation" # "batch" or "evaluation"
  input_image_folder: "./assets/samples"
  input_image_paths: []
  selected_models: ["gpt4o", "granite", "llava34b", "pixtral", "gemma3", "llava-phi3"]

# Component-specific configurations
steps:
  run_ocr:
    parameters:
      models: ["gpt4o", "granite", "llava34b"]
      image_folder: "./assets/samples"
      image_paths: []
      custom_prompt: null
    enable_cache: False

  save_ocr_results:
    parameters:
      save_locally: True
      output_dir: "ocr_results"

  evaluate_models:
    parameters:
      custom_prompt: null
      ground_truth_folder: "ground_truth_texts"
      ground_truth_files: []
      result_files: []
      results_dir: "ocr_results"
      visualization_output_dir: "visualizations"
    enable_cache: False

  save_visualization:
    parameters:
      save_locally: True
      output_dir: "visualizations"

# Models registry - maintains metadata about available models
models_registry:
  - name: "mistral/pixtral-12b-2409"
    shorthand: "pixtral"
    ocr_processor: "litellm"
    provider: "mistral"

  - name: "gpt-4o-mini"
    shorthand: "gpt4o"
    ocr_processor: "openai"

  - name: "gemma3:27b"
    shorthand: "gemma3"
    ocr_processor: "ollama"

  - name: "llava:34b"
    shorthand: "llava34b"
    ocr_processor: "ollama"

  - name: "llava-phi3"
    shorthand: "llava-phi3"
    ocr_processor: "ollama"

  - name: "granite3.2-vision"
    shorthand: "granite"
    ocr_processor: "ollama"
